
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Bagging and Random Forests &#8212; Machine Learning Scientist with Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Boosting" href="Machine-Learning-with-Tree-Based-Models-in-Python-4.html" />
    <link rel="prev" title="The Bias-Variance Tradeoff" href="Machine-Learning-with-Tree-Based-Models-in-Python-2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning Scientist with Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Supervised-Learning-with-scikit-learn-0.html">
   Supervised Learning with scikit-learn
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Supervised-Learning-with-scikit-learn-1.html">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Supervised-Learning-with-scikit-learn-2.html">
     Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Supervised-Learning-with-scikit-learn-3.html">
     Fine-Tuning Your Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Supervised-Learning-with-scikit-learn-4.html">
     Preprocessing and Pipelines
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Unsupervised-Learning-in-Python-0.html">
   Unsupervised Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Unsupervised-Learning-in-Python-1.html">
     Clustering for dataset exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Unsupervised-Learning-in-Python-2.html">
     Visualization with hierarchical clustering and t-SNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Unsupervised-Learning-in-Python-3.html">
     Decorrelating your data and dimension reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Unsupervised-Learning-in-Python-4.html">
     Discovering interpretable features
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Linear-Classifiers-in-Python-0.html">
   Linear Classifiers in Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear-Classifiers-in-Python-1.html">
     Applying logistic regression and SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear-Classifiers-in-Python-2.html">
     Loss functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear-Classifiers-in-Python-3.html">
     Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear-Classifiers-in-Python-4.html">
     Support Vector Machines
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-0.html">
   Machine Learning with Tree-Based Models in Python
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-1.html">
     Classification and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-2.html">
     The Bias-Variance Tradeoff
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Bagging and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-4.html">
     Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-5.html">
     Model Tuning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-0.html">
   Extreme Gradient Boosting with XGBoost
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-1.html">
     Classification with XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-2.html">
     Regression with XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-3.html">
     Fine-tuning your XGBoost model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-4.html">
     Using XGBoost in pipelines
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/iuvnumath/datacamp-python-ml"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/iuvnumath/datacamp-python-ml/issues/new?title=Issue%20on%20page%20%2FMachine-Learning-with-Tree-Based-Models-in-Python-3.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Machine-Learning-with-Tree-Based-Models-in-Python-3.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bagging">
   Bagging
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-the-bagging-classifier">
     Define the bagging classifier
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluate-bagging-performance">
     Evaluate Bagging performance
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#out-of-bag-evaluation">
   Out of Bag Evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-the-ground">
     Prepare the ground
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oob-score-vs-test-set-score">
     OOB Score vs Test Set Score
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-forests-rf">
   Random Forests (RF)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-an-rf-regressor">
     Train an RF regressor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluate-the-rf-regressor">
     Evaluate the RF regressor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualizing-features-importances">
     Visualizing features importances
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Bagging and Random Forests</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bagging">
   Bagging
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-the-bagging-classifier">
     Define the bagging classifier
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluate-bagging-performance">
     Evaluate Bagging performance
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#out-of-bag-evaluation">
   Out of Bag Evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-the-ground">
     Prepare the ground
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oob-score-vs-test-set-score">
     OOB Score vs Test Set Score
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-forests-rf">
   Random Forests (RF)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-an-rf-regressor">
     Train an RF regressor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluate-the-rf-regressor">
     Evaluate the RF regressor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualizing-features-importances">
     Visualizing features importances
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="bagging-and-random-forests">
<h1>Bagging and Random Forests<a class="headerlink" href="#bagging-and-random-forests" title="Permalink to this headline">#</a></h1>
<p class="chapter__description">
Bagging is an ensemble method involving training the same algorithm many
times using different subsets sampled from the training data. In this
chapter, you’ll understand how bagging can be used to create a tree
ensemble. You’ll also learn how the random forests algorithm can lead to
further ensemble diversity through randomization at the level of each
split in the trees forming the ensemble.
</p>
<section id="bagging">
<h2>Bagging<a class="headerlink" href="#bagging" title="Permalink to this headline">#</a></h2>
<section id="define-the-bagging-classifier">
<h3>Define the bagging classifier<a class="headerlink" href="#define-the-bagging-classifier" title="Permalink to this headline">#</a></h3>
<p>
In the following exercises you’ll work with the
<a href="https://www.kaggle.com/uciml/indian-liver-patient-records">Indian
Liver Patient</a> dataset from the UCI machine learning repository. Your
task is to predict whether a patient suffers from a liver disease using
10 features including Albumin, age and gender. You’ll do so using a
Bagging Classifier.
</p>
<li>
Import <code>DecisionTreeClassifier</code> from
<code>sklearn.tree</code> and <code>BaggingClassifier</code> from
<code>sklearn.ensemble</code>.
</li>
<li>
Instantiate a <code>DecisionTreeClassifier</code> called
<code>dt</code>.
</li>
<li>
Instantiate a <code>BaggingClassifier</code> called <code>bc</code>
consisting of 50 trees.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="c1"># Import BaggingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>

<span class="c1"># Instantiate dt</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Instantiate bc</span>
<span class="n">bc</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p class>
Great! In the following exercise, you’ll train <code>bc</code> and
evaluate its test set performance.
</p>
</section>
<section id="evaluate-bagging-performance">
<h3>Evaluate Bagging performance<a class="headerlink" href="#evaluate-bagging-performance" title="Permalink to this headline">#</a></h3>
<p>
Now that you instantiated the bagging classifier, it’s time to train it
and evaluate its test set accuracy.
</p>
<p>
The Indian Liver Patient dataset is processed for you and split into 80%
train and 20% test. The feature matrices <code>X_train</code> and
<code>X_test</code>, as well as the arrays of labels
<code>y_train</code> and <code>y_test</code> are available in your
workspace. In addition, we have also loaded the bagging classifier
<code>bc</code> that you instantiated in the previous exercise and the
function <code>accuracy_score()</code> from
<code>sklearn.metrics</code>.
</p>
<li>
Fit <code>bc</code> to the training set.
</li>
<li>
Predict the test set labels and assign the result to
<code>y_pred</code>.
</li>
<li>
Determine <code>bc</code>’s test set accuracy.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit bc to the training set</span>
<span class="n">bc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict test set labels</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=1),
##                   n_estimators=50, random_state=1)
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">bc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate acc_test</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set accuracy of bc: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_test</span><span class="p">))</span> 
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## Test set accuracy of bc: 0.70
</pre></div>
</div>
<p class>
Great work! A single tree <code>dt</code> would have achieved an
accuracy of 63% which is 4% lower than <code>bc</code>’s accuracy!
</p>
</section>
</section>
<section id="out-of-bag-evaluation">
<h2>Out of Bag Evaluation<a class="headerlink" href="#out-of-bag-evaluation" title="Permalink to this headline">#</a></h2>
<section id="prepare-the-ground">
<h3>Prepare the ground<a class="headerlink" href="#prepare-the-ground" title="Permalink to this headline">#</a></h3>
<p>
In the following exercises, you’ll compare the OOB accuracy to the test
set accuracy of a bagging classifier trained on the Indian Liver Patient
dataset.
</p>
<p>
In sklearn, you can evaluate the OOB accuracy of an ensemble classifier
by setting the parameter <code>oob_score</code> to <code>True</code>
during instantiation. After training the classifier, the OOB accuracy
can be obtained by accessing the <code>.oob_score\_</code> attribute
from the corresponding instance.
</p>
<p>
In your environment, we have made available the class
<code>DecisionTreeClassifier</code> from <code>sklearn.tree</code>.
</p>
<li>
Import <code>BaggingClassifier</code> from
<code>sklearn.ensemble</code>.
</li>
<li>
Instantiate a <code>DecisionTreeClassifier</code> with
<code>min_samples_leaf</code> set to 8.
</li>
<li>
Instantiate a <code>BaggingClassifier</code> consisting of 50 trees and
set <code>oob_score</code> to <code>True</code>.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="c1"># Import BaggingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>

<span class="c1"># Instantiate dt</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Instantiate bc</span>
<span class="n">bc</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span> 
            <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p class>
Great! In the following exercise, you’ll train <code>bc</code> and
compare its test set accuracy to its OOB accuracy.
</p>
</section>
<section id="oob-score-vs-test-set-score">
<h3>OOB Score vs Test Set Score<a class="headerlink" href="#oob-score-vs-test-set-score" title="Permalink to this headline">#</a></h3>
<p>
Now that you instantiated <code>bc</code>, you will fit it to the
training set and evaluate its test set and OOB accuracies.
</p>
<p>
The dataset is processed for you and split into 80% train and 20% test.
The feature matrices <code>X_train</code> and <code>X_test</code>, as
well as the arrays of labels <code>y_train</code> and
<code>y_test</code> are available in your workspace. In addition, we
have also loaded the classifier <code>bc</code> instantiated in the
previous exercise and the function <code>accuracy_score()</code> from
<code>sklearn.metrics</code>.
</p>
<li>
Fit <code>bc</code> to the training set and predict the test set labels
and assign the results to <code>y_pred</code>.
</li>
<li>
Evaluate the test set accuracy <code>acc_test</code> by calling
<code>accuracy_score</code>.
</li>
<li>
Evaluate <code>bc</code>’s OOB accuracy <code>acc_oob</code> by
extracting the attribute <code>oob_score\_</code> from <code>bc</code>.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit bc to the training set </span>
<span class="n">bc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict test set labels</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## BaggingClassifier(base_estimator=DecisionTreeClassifier(min_samples_leaf=8,
##                                                         random_state=1),
##                   n_estimators=50, oob_score=True, random_state=1)
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">bc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate test set accuracy</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Evaluate OOB accuracy</span>
<span class="n">acc_oob</span> <span class="o">=</span> <span class="n">bc</span><span class="o">.</span><span class="n">oob_score_</span>

<span class="c1"># Print acc_test and acc_oob</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set accuracy: </span><span class="si">{:.3f}</span><span class="s1">, OOB accuracy: </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_test</span><span class="p">,</span> <span class="n">acc_oob</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## Test set accuracy: 0.690, OOB accuracy: 0.687
</pre></div>
</div>
<p class>
Great work! The test set accuracy and the OOB accuracy of
<code>bc</code> are both roughly equal to 70%!
</p>
</section>
</section>
<section id="random-forests-rf">
<h2>Random Forests (RF)<a class="headerlink" href="#random-forests-rf" title="Permalink to this headline">#</a></h2>
<section id="train-an-rf-regressor">
<h3>Train an RF regressor<a class="headerlink" href="#train-an-rf-regressor" title="Permalink to this headline">#</a></h3>
<p>
In the following exercises you’ll predict bike rental demand in the
Capital Bikeshare program in Washington, D.C using historical weather
data from the
<a href="https://www.kaggle.com/c/bike-sharing-demand">Bike Sharing
Demand</a> dataset available through Kaggle. For this purpose, you will
be using the random forests algorithm. As a first step, you’ll define a
random forests regressor and fit it to the training set.
</p>
<p>
The dataset is processed for you and split into 80% train and 20% test.
The features matrix <code>X_train</code> and the array
<code>y_train</code> are available in your workspace.
</p>
<li>
Import <code>RandomForestRegressor</code> from
<code>sklearn.ensemble</code>.
</li>
<li>
Instantiate a <code>RandomForestRegressor</code> called <code>rf</code>
consisting of 25 trees.
</li>
<li>
Fit <code>rf</code> to the training set.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Instantiate rf</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            
<span class="c1"># Fit rf to the training set    </span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> 
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## RandomForestRegressor(n_estimators=25, random_state=2)
</pre></div>
</div>
<p class>
Great work! Next comes the test set RMSE evaluation part.
</p>
</section>
<section id="evaluate-the-rf-regressor">
<h3>Evaluate the RF regressor<a class="headerlink" href="#evaluate-the-rf-regressor" title="Permalink to this headline">#</a></h3>
<p>
You’ll now evaluate the test set RMSE of the random forests regressor
<code>rf</code> that you trained in the previous exercise.
</p>
<p>
The dataset is processed for you and split into 80% train and 20% test.
The features matrix <code>X_test</code>, as well as the array
<code>y_test</code> are available in your workspace. In addition, we
have also loaded the model <code>rf</code> that you trained in the
previous exercise.
</p>
<li>
Import <code>mean_squared_error</code> from <code>sklearn.metrics</code>
as <code>MSE</code>.
</li>
<li>
Predict the test set labels and assign the result to
<code>y_pred</code>.
</li>
<li>
Compute the test set RMSE and assign it to <code>rmse_test</code>.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import mean_squared_error as MSE</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span> <span class="k">as</span> <span class="n">MSE</span>

<span class="c1"># Predict the test set labels</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate the test set RMSE</span>
<span class="n">rmse_test</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span>

<span class="c1"># Print rmse_test</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test set RMSE of rf: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rmse_test</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## Test set RMSE of rf: 0.43
</pre></div>
</div>
<p class>
Great work! You can try training a single CART on the same dataset. The
test set RMSE achieved by <code>rf</code> is significantly smaller than
that achieved by a single CART!
</p>
</section>
<section id="visualizing-features-importances">
<h3>Visualizing features importances<a class="headerlink" href="#visualizing-features-importances" title="Permalink to this headline">#</a></h3>
<p>
In this exercise, you’ll determine which features were the most
predictive according to the random forests regressor <code>rf</code>
that you trained in a previous exercise.
</p>
<p>
For this purpose, you’ll draw a horizontal barplot of the feature
importance as assessed by <code>rf</code>. Fortunately, this can be done
easily thanks to plotting capabilities of <code>pandas</code>.
</p>
<p>
We have created a <code>pandas.Series</code> object called
<code>importances</code> containing the feature names as
<code>index</code> and their importances as values. In addition,
<code>matplotlib.pyplot</code> is available as <code>plt</code> and
<code>pandas</code> as <code>pd</code>.
</p>
<li>
Call the <code>.sort_values()</code> method on <code>importances</code>
and assign the result to <code>importances_sorted</code>.
</li>
<li>
<p>Call the <code>.plot()</code> method on <code>importances_sorted</code>
and set the arguments:</p>
<li>
<code>kind</code> to <code>‘barh’</code>
</li>
<li>
<code>color</code> to <code>‘lightgreen’</code>
</li>
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a pd.Series of features importances</span>
<span class="n">importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">rf</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span>
                        <span class="n">index</span><span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># Sort importances</span>
<span class="n">importances_sorted</span> <span class="o">=</span> <span class="n">importances</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span>

<span class="c1"># Draw a horizontal barplot of importances_sorted</span>
<span class="n">importances_sorted</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;barh&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Features Importances&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="Machine-Learning-with-Tree-Based-Models-in-Python_files/figure-markdown_github/unnamed-chunk-22-5.png" width="672" />
<p class>
Apparently, <code>hr</code> and <code>workingday</code> are the most
important features according to <code>rf</code>. The importances of
these two features add up to more than 90%!
</p></section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Machine-Learning-with-Tree-Based-Models-in-Python-2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">The Bias-Variance Tradeoff</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Machine-Learning-with-Tree-Based-Models-in-Python-4.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Boosting</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book Community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>