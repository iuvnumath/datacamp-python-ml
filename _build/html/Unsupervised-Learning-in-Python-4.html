
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Discovering interpretable features &#8212; Machine Learning Scientist with Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Linear Classifiers in Python" href="Linear-Classifiers-in-Python-0.html" />
    <link rel="prev" title="Decorrelating your data and dimension reduction" href="Unsupervised-Learning-in-Python-3.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning Scientist with Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Supervised-Learning-with-scikit-learn-0.html">
   Supervised Learning with scikit-learn
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Supervised-Learning-with-scikit-learn-1.html">
     Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Supervised-Learning-with-scikit-learn-2.html">
     Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Supervised-Learning-with-scikit-learn-3.html">
     Fine-Tuning Your Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Supervised-Learning-with-scikit-learn-4.html">
     Preprocessing and Pipelines
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="Unsupervised-Learning-in-Python-0.html">
   Unsupervised Learning in Python
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Unsupervised-Learning-in-Python-1.html">
     Clustering for dataset exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Unsupervised-Learning-in-Python-2.html">
     Visualization with hierarchical clustering and t-SNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Unsupervised-Learning-in-Python-3.html">
     Decorrelating your data and dimension reduction
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Discovering interpretable features
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Linear-Classifiers-in-Python-0.html">
   Linear Classifiers in Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear-Classifiers-in-Python-1.html">
     Applying logistic regression and SVM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear-Classifiers-in-Python-2.html">
     Loss functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear-Classifiers-in-Python-3.html">
     Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Linear-Classifiers-in-Python-4.html">
     Support Vector Machines
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-0.html">
   Machine Learning with Tree-Based Models in Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-1.html">
     Classification and Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-2.html">
     The Bias-Variance Tradeoff
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-3.html">
     Bagging and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-4.html">
     Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Machine-Learning-with-Tree-Based-Models-in-Python-5.html">
     Model Tuning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-0.html">
   Extreme Gradient Boosting with XGBoost
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-1.html">
     Classification with XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-2.html">
     Regression with XGBoost
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-3.html">
     Fine-tuning your XGBoost model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Extreme-Gradient-Boosting-with-XGBoost-4.html">
     Using XGBoost in pipelines
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/iuvnumath/datacamp-python-ml"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/iuvnumath/datacamp-python-ml/issues/new?title=Issue%20on%20page%20%2FUnsupervised-Learning-in-Python-4.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Unsupervised-Learning-in-Python-4.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-negative-matrix-factorization-nmf">
   Non-negative matrix factorization (NMF)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#non-negative-data">
     Non-negative data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-applied-to-wikipedia-articles">
     NMF applied to Wikipedia articles
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-features-of-the-wikipedia-articles">
     NMF features of the Wikipedia articles
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-reconstructs-samples">
     NMF reconstructs samples
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nmf-learns-interpretable-parts">
   NMF learns interpretable parts
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-learns-topics-of-documents">
     NMF learns topics of documents
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-the-led-digits-dataset">
     Explore the LED digits dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-learns-the-parts-of-images">
     NMF learns the parts of images
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pca-doesnt-learn-parts">
     PCA doesn’t learn parts
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-recommender-systems-using-nmf">
   Building recommender systems using NMF
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#which-articles-are-similar-to-cristiano-ronaldo">
     Which articles are similar to ‘Cristiano Ronaldo’?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recommend-musical-artists-part-i">
     Recommend musical artists part I
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recommend-musical-artists-part-ii">
     Recommend musical artists part II
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#final-thoughts">
   Final thoughts
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Final thoughts
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#congratulations">
     Congratulations!
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Discovering interpretable features</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-negative-matrix-factorization-nmf">
   Non-negative matrix factorization (NMF)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#non-negative-data">
     Non-negative data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-applied-to-wikipedia-articles">
     NMF applied to Wikipedia articles
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-features-of-the-wikipedia-articles">
     NMF features of the Wikipedia articles
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-reconstructs-samples">
     NMF reconstructs samples
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nmf-learns-interpretable-parts">
   NMF learns interpretable parts
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-learns-topics-of-documents">
     NMF learns topics of documents
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explore-the-led-digits-dataset">
     Explore the LED digits dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nmf-learns-the-parts-of-images">
     NMF learns the parts of images
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pca-doesnt-learn-parts">
     PCA doesn’t learn parts
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-recommender-systems-using-nmf">
   Building recommender systems using NMF
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#which-articles-are-similar-to-cristiano-ronaldo">
     Which articles are similar to ‘Cristiano Ronaldo’?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recommend-musical-artists-part-i">
     Recommend musical artists part I
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recommend-musical-artists-part-ii">
     Recommend musical artists part II
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#final-thoughts">
   Final thoughts
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Final thoughts
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#congratulations">
     Congratulations!
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="discovering-interpretable-features">
<h1>Discovering interpretable features<a class="headerlink" href="#discovering-interpretable-features" title="Permalink to this headline">#</a></h1>
<p class="chapter__description">
In this chapter, you’ll learn about a dimension reduction technique
called “Non-negative matrix factorization” (“NMF”) that expresses
samples as combinations of interpretable parts. For example, it
expresses documents as combinations of topics, and images in terms of
commonly occurring visual patterns. You’ll also learn to use NMF to
build recommender systems that can find you similar articles to read, or
musical artists that match your listening history!
</p>
<section id="non-negative-matrix-factorization-nmf">
<h2>Non-negative matrix factorization (NMF)<a class="headerlink" href="#non-negative-matrix-factorization-nmf" title="Permalink to this headline">#</a></h2>
<section id="non-negative-data">
<h3>Non-negative data<a class="headerlink" href="#non-negative-data" title="Permalink to this headline">#</a></h3>
<p>
Which of the following 2-dimensional arrays are examples of non-negative
data?
</p>
<ol>
<li>
A tf-idf word-frequency array.
</li>
<li>
An array daily stock market price movements (up and down), where each
row represents a company.
</li>
<li>
An array where rows are customers, columns are products and entries are
0 or 1, indicating whether a customer has purchased a product.
</li>
</ol>
<ul class="contains-task-list simple">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> 1 only</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> 2 and 3</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" checked="checked" disabled="disabled" type="checkbox"> 1 and 3</p></li>
</ul>
<p class="dc-completion-pane__message dc-u-maxw-100pc">
Well done! Stock prices can go down as well as up, so an array of daily
stock market price movements is not an example of non-negative data.
</p>
</section>
<section id="nmf-applied-to-wikipedia-articles">
<h3>NMF applied to Wikipedia articles<a class="headerlink" href="#nmf-applied-to-wikipedia-articles" title="Permalink to this headline">#</a></h3>
<p>
In the video, you saw NMF applied to transform a toy word-frequency
array. Now it’s your turn to apply NMF, this time using the tf-idf
word-frequency array of Wikipedia articles, given as a csr matrix
<code>articles</code>. Here, fit the model and transform the articles.
In the next exercise, you’ll explore the result.
</p>
<li>
Import <code>NMF</code> from <code>sklearn.decomposition</code>.
</li>
<li>
Create an <code>NMF</code> instance called <code>model</code> with
<code>6</code> components.
</li>
<li>
Fit the model to the word count data <code>articles</code>.
</li>
<li>
Use the <code>.transform()</code> method of <code>model</code> to
transform <code>articles</code>, and assign the result to
<code>nmf_features</code>.
</li>
<li>
Print <code>nmf_features</code> to get a first idea what it looks like
(<code>.round(2)</code> rounds the entries to 2 decimal places.)
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import NMF</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">NMF</span>

<span class="c1"># Create an NMF instance: model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<span class="c1"># Fit the model to articles</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">articles</span><span class="p">)</span>

<span class="c1"># Transform the articles: nmf_features</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## NMF(n_components=6)
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nmf_features</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">articles</span><span class="p">)</span>

<span class="c1"># Print the NMF features</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nmf_features</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## [[0.   0.   0.   0.   0.   0.44]
##  [0.   0.   0.   0.   0.   0.57]
##  [0.   0.   0.   0.   0.   0.4 ]
##  [0.   0.   0.   0.   0.   0.38]
##  [0.   0.   0.   0.   0.   0.49]
##  [0.01 0.01 0.01 0.03 0.   0.33]
##  [0.   0.   0.02 0.   0.01 0.36]
##  [0.   0.   0.   0.   0.   0.49]
##  [0.02 0.01 0.   0.02 0.03 0.48]
##  [0.01 0.03 0.03 0.07 0.02 0.34]
##  [0.   0.   0.53 0.   0.03 0.  ]
##  [0.   0.   0.36 0.   0.   0.  ]
##  [0.01 0.01 0.31 0.06 0.01 0.02]
##  [0.   0.01 0.34 0.01 0.   0.  ]
##  [0.   0.   0.43 0.   0.04 0.  ]
##  [0.   0.   0.48 0.   0.   0.  ]
##  [0.01 0.02 0.38 0.03 0.   0.01]
##  [0.   0.   0.48 0.   0.   0.  ]
##  [0.   0.01 0.55 0.   0.   0.  ]
##  [0.   0.   0.47 0.   0.   0.  ]
##  [0.   0.01 0.02 0.52 0.06 0.01]
##  [0.   0.   0.   0.51 0.   0.  ]
##  [0.   0.01 0.   0.42 0.   0.  ]
##  [0.   0.   0.   0.44 0.   0.  ]
##  [0.   0.   0.   0.5  0.   0.  ]
##  [0.1  0.09 0.   0.38 0.   0.01]
##  [0.   0.   0.   0.57 0.   0.01]
##  [0.01 0.01 0.   0.47 0.   0.01]
##  [0.   0.   0.   0.58 0.   0.  ]
##  [0.   0.   0.   0.53 0.01 0.01]
##  [0.   0.41 0.   0.   0.   0.  ]
##  [0.   0.61 0.   0.01 0.   0.  ]
##  [0.01 0.27 0.   0.02 0.01 0.  ]
##  [0.   0.64 0.   0.   0.   0.  ]
##  [0.   0.61 0.   0.   0.   0.  ]
##  [0.   0.34 0.   0.   0.   0.  ]
##  [0.01 0.32 0.02 0.   0.01 0.  ]
##  [0.01 0.21 0.01 0.05 0.02 0.01]
##  [0.01 0.47 0.   0.02 0.   0.  ]
##  [0.   0.64 0.   0.   0.   0.  ]
##  [0.   0.   0.   0.   0.48 0.  ]
##  [0.   0.   0.   0.   0.49 0.  ]
##  [0.   0.   0.   0.   0.38 0.01]
##  [0.   0.   0.   0.01 0.54 0.  ]
##  [0.   0.   0.01 0.   0.42 0.  ]
##  [0.   0.   0.   0.   0.51 0.  ]
##  [0.   0.   0.   0.   0.37 0.  ]
##  [0.   0.   0.04 0.   0.23 0.  ]
##  [0.01 0.   0.02 0.01 0.33 0.04]
##  [0.   0.   0.   0.   0.42 0.  ]
##  [0.31 0.   0.   0.   0.   0.  ]
##  [0.37 0.   0.   0.   0.   0.  ]
##  [0.4  0.03 0.   0.02 0.   0.02]
##  [0.38 0.   0.   0.04 0.   0.01]
##  [0.44 0.   0.   0.   0.   0.  ]
##  [0.46 0.   0.   0.   0.   0.  ]
##  [0.28 0.   0.   0.05 0.   0.02]
##  [0.45 0.   0.   0.   0.01 0.  ]
##  [0.29 0.01 0.01 0.01 0.19 0.01]
##  [0.38 0.01 0.   0.1  0.01 0.  ]]
</pre></div>
</div>
<p class>
Fantastic - let’s explore the meaning of these features in the next
exercise!
</p>
</section>
<section id="nmf-features-of-the-wikipedia-articles">
<h3>NMF features of the Wikipedia articles<a class="headerlink" href="#nmf-features-of-the-wikipedia-articles" title="Permalink to this headline">#</a></h3>
<p>
Now you will explore the NMF features you created in the previous
exercise. A solution to the previous exercise has been pre-loaded, so
the array <code>nmf_features</code> is available. Also available is a
list <code>titles</code> giving the title of each Wikipedia article.
</p>
<p>
When investigating the features, notice that for both actors, the NMF
feature 3 has by far the highest value. This means that both articles
are reconstructed using mainly the 3rd NMF component. In the next video,
you’ll see why: NMF components represent topics (for instance, acting!).
</p>
<li>
Import <code>pandas</code> as <code>pd</code>.
</li>
<li>
Create a DataFrame <code>df</code> from <code>nmf_features</code> using
<code>pd.DataFrame()</code>. Set the index to <code>titles</code> using
<code>index=titles</code>.
</li>
<li>
Use the <code>.loc\[\]</code> accessor of <code>df</code> to select the
row with title <code>‘Anne Hathaway’</code>, and print the result. These
are the NMF features for the article about the actress Anne Hathaway.
</li>
<li>
Repeat the last step for <code>‘Denzel Washington’</code> (another
actor).
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Create a pandas DataFrame: df</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">nmf_features</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">titles</span><span class="p">)</span>

<span class="c1"># Print the row for &#39;Anne Hathaway&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;Anne Hathaway&#39;</span><span class="p">])</span>

<span class="c1"># Print the row for &#39;Denzel Washington&#39;</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## 0    0.003845
## 1    0.000000
## 2    0.000000
## 3    0.575667
## 4    0.000000
## 5    0.000000
## Name: Anne Hathaway, dtype: float64
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;Denzel Washington&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## 0    0.000000
## 1    0.005601
## 2    0.000000
## 3    0.422348
## 4    0.000000
## 5    0.000000
## Name: Denzel Washington, dtype: float64
</pre></div>
</div>
<p class>
Great work! Notice that for both actors, the NMF feature 3 has by far
the highest value. This means that both articles are reconstructed using
mainly the 3rd NMF component. In the next video, you’ll see why: NMF
components represent topics (for instance, acting!).
</p>
</section>
<section id="nmf-reconstructs-samples">
<h3>NMF reconstructs samples<a class="headerlink" href="#nmf-reconstructs-samples" title="Permalink to this headline">#</a></h3>
<p>
In this exercise, you’ll check your understanding of how NMF
reconstructs samples from its components using the NMF feature values.
On the right are the components of an NMF model. If the NMF feature
values of a sample are <code>\[2, 1\]</code>, then which of the
following is <em>most likely</em> to represent the original sample? A
pen and paper will help here! You have to apply the same technique Ben
used in the video to reconstruct the sample <code>\[0.1203 0.1764 0.3195
0.141\]</code>.
</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># edited/added</span>
<span class="n">sample_feature</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">components</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span> <span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.</span> <span class="p">],</span>
                       <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">]])</span>
<span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">sample_feature</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">components</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## array([2.2, 1.1, 2.1])
</pre></div>
</div>
<ul class="contains-task-list simple">
<li class="task-list-item"><p><input class="task-list-item-checkbox" checked="checked" disabled="disabled" type="checkbox"> <code>[2.2, 1.1, 2.1]</code></p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <code>[0.5, 1.6, 3.1]</code></p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> <code>[-4.0, 1.0, -2.0]</code></p></li>
</ul>
<p class>
Well done, you’ve got it!
</p>
</section>
</section>
<section id="nmf-learns-interpretable-parts">
<h2>NMF learns interpretable parts<a class="headerlink" href="#nmf-learns-interpretable-parts" title="Permalink to this headline">#</a></h2>
<section id="nmf-learns-topics-of-documents">
<h3>NMF learns topics of documents<a class="headerlink" href="#nmf-learns-topics-of-documents" title="Permalink to this headline">#</a></h3>
<p>
In the video, you learned when NMF is applied to documents, the
components correspond to topics of documents, and the NMF features
reconstruct the documents from the topics. Verify this for yourself for
the NMF model that you built earlier using the Wikipedia articles.
Previously, you saw that the 3rd NMF feature value was high for the
articles about actors Anne Hathaway and Denzel Washington. In this
exercise, identify the topic of the corresponding NMF component.
</p>
<p>
The NMF model you built earlier is available as <code>model</code>,
while <code>words</code> is a list of the words that label the columns
of the word-frequency array.
</p>
<p>
After you are done, take a moment to recognize the topic that the
articles about Anne Hathaway and Denzel Washington have in common!
</p>
<li>
Import <code>pandas</code> as <code>pd</code>.
</li>
<li>
Create a DataFrame <code>components_df</code> from
<code>model.components\_</code>, setting <code>columns=words</code> so
that columns are labeled by the words.
</li>
<li>
Print <code>components_df.shape</code> to check the dimensions of the
DataFrame.
</li>
<li>
Use the <code>.iloc\[\]</code> accessor on the DataFrame
<code>components_df</code> to select row <code>3</code>. Assign the
result to <code>component</code>.
</li>
<li>
Call the <code>.nlargest()</code> method of <code>component</code>, and
print the result. This gives the five words with the highest values for
that component.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># edited/added</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;archive/Unsupervised-Learning-in-Python/datasets/wikipedia-vocabulary-utf8.txt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
    
<span class="c1"># Import pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Create a DataFrame: components_df</span>
<span class="n">components_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">words</span><span class="p">)</span>

<span class="c1"># Print the shape of the DataFrame</span>
<span class="nb">print</span><span class="p">(</span><span class="n">components_df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Select row 3: component</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## (6, 13125)
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">component</span> <span class="o">=</span> <span class="n">components_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># Print result of nlargest</span>
<span class="nb">print</span><span class="p">(</span><span class="n">component</span><span class="o">.</span><span class="n">nlargest</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## film       0.627924
## award      0.253151
## starred    0.245303
## role       0.211467
## actress    0.186412
## Name: 3, dtype: float64
</pre></div>
</div>
<p class>
Great work! Take a moment to recognise the topics that the articles
about Anne Hathaway and Denzel Washington have in common!
</p>
</section>
<section id="explore-the-led-digits-dataset">
<h3>Explore the LED digits dataset<a class="headerlink" href="#explore-the-led-digits-dataset" title="Permalink to this headline">#</a></h3>
<p>
In the following exercises, you’ll use NMF to decompose grayscale images
into their commonly occurring patterns. Firstly, explore the image
dataset and see how it is encoded as an array. You are given 100 images
as a 2D array <code>samples</code>, where each row represents a single
13x8 image. The images in your dataset are pictures of a LED digital
display.
</p>
<li>
Import <code>matplotlib.pyplot</code> as <code>plt</code>.
</li>
<li>
Select row <code>0</code> of <code>samples</code> and assign the result
to <code>digit</code>. For example, to select column <code>2</code> of
an array <code>a</code>, you could use <code>a\[:,2\]</code>. Remember
that since <code>samples</code> is a NumPy array, you can’t use the
<code>.loc\[\]</code> or <code>iloc\[\]</code> accessors to select
specific rows or columns.
</li>
<li>
Print <code>digit</code>. This has been done for you. Notice that it is
a 1D array of 0s and 1s.
</li>
<li>
Use the <code>.reshape()</code> method of <code>digit</code> to get a 2D
array with shape <code>(13, 8)</code>. Assign the result to
<code>bitmap</code>.
</li>
<li>
Print <code>bitmap</code>, and notice that the 1s show the digit 7!
</li>
<li>
Use the <code>plt.imshow()</code> function to display
<code>bitmap</code> as an image.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># edited/added</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;archive/Unsupervised-Learning-in-Python/datasets/lcd-digits.csv&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span>
<span class="n">digit</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Import pyplot</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Select the 0th row: digit</span>
<span class="n">digit</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span>

<span class="c1"># Print digit</span>
<span class="nb">print</span><span class="p">(</span><span class="n">digit</span><span class="p">)</span>

<span class="c1"># Reshape digit to a 13x8 array: bitmap</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
##  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
##  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
##  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
##  0. 0. 0. 0. 0. 0. 0. 0.]
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bitmap</span> <span class="o">=</span> <span class="n">digit</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">13</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># Print bitmap</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bitmap</span><span class="p">)</span>

<span class="c1"># Use plt.imshow to display bitmap</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## [[0. 0. 0. 0. 0. 0. 0. 0.]
##  [0. 0. 1. 1. 1. 1. 0. 0.]
##  [0. 0. 0. 0. 0. 0. 1. 0.]
##  [0. 0. 0. 0. 0. 0. 1. 0.]
##  [0. 0. 0. 0. 0. 0. 1. 0.]
##  [0. 0. 0. 0. 0. 0. 1. 0.]
##  [0. 0. 0. 0. 0. 0. 0. 0.]
##  [0. 0. 0. 0. 0. 0. 1. 0.]
##  [0. 0. 0. 0. 0. 0. 1. 0.]
##  [0. 0. 0. 0. 0. 0. 1. 0.]
##  [0. 0. 0. 0. 0. 0. 1. 0.]
##  [0. 0. 0. 0. 0. 0. 0. 0.]
##  [0. 0. 0. 0. 0. 0. 0. 0.]]
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">bitmap</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## &lt;matplotlib.colorbar.Colorbar object at 0x7ffcdaca82e0&gt;
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="Unsupervised-Learning-in-Python_files/figure-markdown_github/unnamed-chunk-29-25.png" width="672" />
<p class>
Excellent job! You’ll explore this dataset further in the next exercise
and see for yourself how NMF can learn the parts of images.
</p>
</section>
<section id="nmf-learns-the-parts-of-images">
<h3>NMF learns the parts of images<a class="headerlink" href="#nmf-learns-the-parts-of-images" title="Permalink to this headline">#</a></h3>
<p>
Now use what you’ve learned about NMF to decompose the digits dataset.
You are again given the digit images as a 2D array <code>samples</code>.
This time, you are also provided with a function
<code>show_as_image()</code> that displays the image encoded by any 1D
array:
</p>
<pre><code>def show_as_image(sample):
    bitmap = sample.reshape((13, 8))
    plt.figure()
    plt.imshow(bitmap, cmap='gray', interpolation='nearest')
    plt.colorbar()
    plt.show()
</code></pre>
<p>
After you are done, take a moment to look through the plots and notice
how NMF has expressed the digit as a sum of the components!
</p>
<li>
Import <code>NMF</code> from <code>sklearn.decomposition</code>.
</li>
<li>
Create an <code>NMF</code> instance called <code>model</code> with
<code>7</code> components. (7 is the number of cells in an LED display).
</li>
<li>
Apply the <code>.fit_transform()</code> method of <code>model</code> to
<code>samples</code>. Assign the result to <code>features</code>.
</li>
<li>
To each component of the model (accessed via
<code>model.components\_</code>), apply the <code>show_as_image()</code>
function to that component inside the loop.
</li>
<li>
Assign the row <code>0</code> of <code>features</code> to
<code>digit_features</code>.
</li>
<li>
Print <code>digit_features</code>.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># edited/added</span>
<span class="k">def</span> <span class="nf">show_as_image</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
    <span class="n">bitmap</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">13</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">bitmap</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
    
<span class="c1"># Import NMF</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">NMF</span>

<span class="c1"># Create an NMF model: model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="c1"># Apply fit_transform to samples: features</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

<span class="c1"># Call show_as_image on each component</span>
<span class="k">for</span> <span class="n">component</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">components_</span><span class="p">:</span>
    <span class="n">show_as_image</span><span class="p">(</span><span class="n">component</span><span class="p">)</span>
    
<span class="c1"># Select the 0th row of features: digit_features</span>
<span class="n">digit_features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span>

<span class="c1"># Print digit_features</span>
<span class="nb">print</span><span class="p">(</span><span class="n">digit_features</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## [4.76823559e-01 0.00000000e+00 0.00000000e+00 5.90605054e-01
##  4.81559442e-01 0.00000000e+00 7.37546142e-16]
</pre></div>
</div>
<p class>
Great work! Take a moment to look through the plots and notice how NMF
has expressed the digit as a sum of the components!
</p>
</section>
<section id="pca-doesnt-learn-parts">
<h3>PCA doesn’t learn parts<a class="headerlink" href="#pca-doesnt-learn-parts" title="Permalink to this headline">#</a></h3>
<p>
Unlike NMF, PCA <em>doesn’t</em> learn the parts of things. Its
components do not correspond to topics (in the case of documents) or to
parts of images, when trained on images. Verify this for yourself by
inspecting the components of a PCA model fit to the dataset of LED digit
images from the previous exercise. The images are available as a 2D
array <code>samples</code>. Also available is a modified version of the
<code>show_as_image()</code> function which colors a pixel red if the
value is negative.
</p>
<p>
After submitting the answer, notice that the components of PCA do not
represent meaningful parts of images of LED digits!
</p>
<li>
Import <code>PCA</code> from <code>sklearn.decomposition</code>.
</li>
<li>
Create a <code>PCA</code> instance called <code>model</code> with
<code>7</code> components.
</li>
<li>
Apply the <code>.fit_transform()</code> method of <code>model</code> to
<code>samples</code>. Assign the result to <code>features</code>.
</li>
<li>
To each component of the model (accessed via
<code>model.components\_</code>), apply the <code>show_as_image()</code>
function to that component inside the loop.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="c1"># Create a PCA instance: model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="c1"># Apply fit_transform to samples: features</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

<span class="c1"># Call show_as_image on each component</span>
<span class="k">for</span> <span class="n">component</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">components_</span><span class="p">:</span>
    <span class="n">show_as_image</span><span class="p">(</span><span class="n">component</span><span class="p">)</span>
</pre></div>
</div>
<p class>
Great work! Notice that the components of PCA do not represent
meaningful parts of images of LED digits!
</p>
</section>
</section>
<section id="building-recommender-systems-using-nmf">
<h2>Building recommender systems using NMF<a class="headerlink" href="#building-recommender-systems-using-nmf" title="Permalink to this headline">#</a></h2>
<section id="which-articles-are-similar-to-cristiano-ronaldo">
<h3>Which articles are similar to ‘Cristiano Ronaldo’?<a class="headerlink" href="#which-articles-are-similar-to-cristiano-ronaldo" title="Permalink to this headline">#</a></h3>
<p>
In the video, you learned how to use NMF features and the cosine
similarity to find similar articles. Apply this to your NMF model for
popular Wikipedia articles, by finding the articles most similar to the
article about the footballer Cristiano Ronaldo. The NMF features you
obtained earlier are available as <code>nmf_features</code>, while
<code>titles</code> is a list of the article titles.
</p>
<li>
Import <code>normalize</code> from <code>sklearn.preprocessing</code>.
</li>
<li>
Apply the <code>normalize()</code> function to
<code>nmf_features</code>. Store the result as
<code>norm_features</code>.
</li>
<li>
Create a DataFrame <code>df</code> from <code>norm_features</code>,
using <code>titles</code> as an index.
</li>
<li>
Use the <code>.loc\[\]</code> accessor of <code>df</code> to select the
row of <code>‘Cristiano Ronaldo’</code>. Assign the result to
<code>article</code>.
</li>
<li>
Apply the <code>.dot()</code> method of <code>df</code> to
<code>article</code> to calculate the cosine similarity of every row
with <code>article</code>.
</li>
<li>
Print the result of the <code>.nlargest()</code> method of
<code>similarities</code> to display the most similar articles. This has
been done for you, so hit ‘Submit Answer’ to see the result!
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform the necessary imports</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">normalize</span>

<span class="c1"># Normalize the NMF features: norm_features</span>
<span class="n">norm_features</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">nmf_features</span><span class="p">)</span>

<span class="c1"># Create a DataFrame: df</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">norm_features</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">titles</span><span class="p">)</span>

<span class="c1"># Select the row corresponding to &#39;Cristiano Ronaldo&#39;: article</span>
<span class="n">article</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;Cristiano Ronaldo&#39;</span><span class="p">]</span>

<span class="c1"># Compute the dot products: similarities</span>
<span class="n">similarities</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">article</span><span class="p">)</span>

<span class="c1"># Display those with the largest cosine similarity</span>
<span class="nb">print</span><span class="p">(</span><span class="n">similarities</span><span class="o">.</span><span class="n">nlargest</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## Cristiano Ronaldo                1.000000
## Franck Ribéry                    0.999972
## Radamel Falcao                   0.999942
## Zlatan Ibrahimović               0.999942
## France national football team    0.999923
## dtype: float64
</pre></div>
</div>
<p class>
Great work - although you may need to know a little about football (or
soccer, depending on where you’re from!) to be able to evaluate for
yourself the quality of the computed similarities!
</p>
</section>
<section id="recommend-musical-artists-part-i">
<h3>Recommend musical artists part I<a class="headerlink" href="#recommend-musical-artists-part-i" title="Permalink to this headline">#</a></h3>
<p>
In this exercise and the next, you’ll use what you’ve learned about NMF
to recommend popular music artists! You are given a sparse array
<code>artists</code> whose rows correspond to artists and whose columns
correspond to users. The entries give the number of times each artist
was listened to by each user.
</p>
<p>
In this exercise, build a pipeline and transform the array into
normalized NMF features. The first step in the pipeline,
<code>MaxAbsScaler</code>, transforms the data so that all users have
the same influence on the model, regardless of how many different
artists they’ve listened to. In the next exercise, you’ll use the
resulting normalized NMF features for recommendation!
</p>
<li>
Import:
<li>
<code>NMF</code> from <code>sklearn.decomposition</code>.
</li>
<li>
<code>Normalizer</code> and <code>MaxAbsScaler</code> from
<code>sklearn.preprocessing</code>.
</li>
<li>
<code>make_pipeline</code> from <code>sklearn.pipeline</code>.
</li>
</li>
<li>
Create an instance of <code>MaxAbsScaler</code> called
<code>scaler</code>.
</li>
<li>
Create an <code>NMF</code> instance with <code>20</code> components
called <code>nmf</code>.
</li>
<li>
Create an instance of <code>Normalizer</code> called
<code>normalizer</code>.
</li>
<li>
Create a pipeline called <code>pipeline</code> that chains together
<code>scaler</code>, <code>nmf</code>, and <code>normalizer</code>.
</li>
<li>
Apply the <code>.fit_transform()</code> method of <code>pipeline</code>
to <code>artists</code>. Assign the result to
<code>norm_features</code>.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># edited/added</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">coo_matrix</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;archive/Unsupervised-Learning-in-Python/datasets/scrobbler-small-sample.csv&#39;</span><span class="p">)</span>
<span class="n">artists1</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;artist_offset&#39;</span><span class="p">,</span> <span class="s1">&#39;user_offset&#39;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>
<span class="n">row_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">artists1</span><span class="p">[</span><span class="s1">&#39;artist_offset&#39;</span><span class="p">])</span>
<span class="n">col_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">artists1</span><span class="p">[</span><span class="s1">&#39;user_offset&#39;</span><span class="p">])</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">artists1</span><span class="p">[</span><span class="s1">&#39;playcount&#39;</span><span class="p">])</span>
<span class="n">artists</span> <span class="o">=</span> <span class="n">coo_matrix</span><span class="p">((</span><span class="n">data1</span><span class="p">,</span> <span class="p">(</span><span class="n">row_ind</span><span class="p">,</span> <span class="n">col_ind</span><span class="p">)))</span>

<span class="c1"># Perform the necessary imports</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">NMF</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Normalizer</span><span class="p">,</span> <span class="n">MaxAbsScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="c1"># Create a MaxAbsScaler: scaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MaxAbsScaler</span><span class="p">()</span>

<span class="c1"># Create an NMF model: nmf</span>
<span class="n">nmf</span> <span class="o">=</span> <span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="c1"># Create a Normalizer: normalizer</span>
<span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span>

<span class="c1"># Create a pipeline: pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">nmf</span><span class="p">,</span> <span class="n">normalizer</span><span class="p">)</span>

<span class="c1"># Apply fit_transform to artists: norm_features</span>
<span class="n">norm_features</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">artists</span><span class="p">)</span>
</pre></div>
</div>
<p class>
Excellent work - now that you’ve computed the normalized NMF features,
you’ll use them in the next exercise to recommend musical artists!
</p>
</section>
<section id="recommend-musical-artists-part-ii">
<h3>Recommend musical artists part II<a class="headerlink" href="#recommend-musical-artists-part-ii" title="Permalink to this headline">#</a></h3>
<p>
Suppose you were a big fan of Bruce Springsteen - which other musical
artists might you like? Use your NMF features from the previous exercise
and the cosine similarity to find similar musical artists. A solution to
the previous exercise has been run, so <code>norm_features</code> is an
array containing the normalized NMF features as rows. The names of the
musical artists are available as the list <code>artist_names</code>.
</p>
<li>
Import <code>pandas</code> as <code>pd</code>.
</li>
<li>
Create a DataFrame <code>df</code> from <code>norm_features</code>,
using <code>artist_names</code> as an index.
</li>
<li>
Use the <code>.loc\[\]</code> accessor of <code>df</code> to select the
row of <code>‘Bruce Springsteen’</code>. Assign the result to
<code>artist</code>.
</li>
<li>
Apply the <code>.dot()</code> method of <code>df</code> to
<code>artist</code> to calculate the dot product of every row with
<code>artist</code>. Save the result as <code>similarities</code>.
</li>
<li>
Print the result of the <code>.nlargest()</code> method of
<code>similarities</code> to display the artists most similar to
<code>‘Bruce Springsteen’</code>.
</li>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># edited/added</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;archive/Unsupervised-Learning-in-Python/datasets/artists.csv&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">artist_names</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1"># Import pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Create a DataFrame: df</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">norm_features</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">artist_names</span><span class="p">)</span>

<span class="c1"># Select row of &#39;Bruce Springsteen&#39;: artist</span>
<span class="n">artist</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s1">&#39;Bruce Springsteen&#39;</span><span class="p">]</span>

<span class="c1"># Compute cosine similarities: similarities</span>
<span class="n">similarities</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">artist</span><span class="p">)</span>

<span class="c1"># Display those with highest cosine similarity</span>
<span class="nb">print</span><span class="p">(</span><span class="n">similarities</span><span class="o">.</span><span class="n">nlargest</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>## Bruce Springsteen    1.000000
## Neil Young           0.959757
## Leonard Cohen        0.917936
## Van Morrison         0.885436
## Bob Dylan            0.866791
## dtype: float64
</pre></div>
</div>
<p class>
Well done, and congratulations on reaching the end of the course!
</p>
</section>
</section>
<section id="final-thoughts">
<h2>Final thoughts<a class="headerlink" href="#final-thoughts" title="Permalink to this headline">#</a></h2>
<section id="id1">
<h3>Final thoughts<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>Congratulations, you sure have come a long way! You’ve learned all about
Unsupervised Learning, and applied the techniques to real-world
datasets, and built your knowledge of Python along the way. In
particular, you’ve become a whiz at using scikit-learn and scipy for
unsupervised learning challenges. You have harnessed both clustering and
dimension reduction techniques to tackle serious problems with
real-world datasets, such as clustering Wikipedia documents by the words
they contain, and recommending musical artists to consumers.</p>
</section>
<section id="congratulations">
<h3>Congratulations!<a class="headerlink" href="#congratulations" title="Permalink to this headline">#</a></h3>
<p>You are now equipped to face a whole range of new challenges.
Congratulations, once again, and keep coding!</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Unsupervised-Learning-in-Python-3.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Decorrelating your data and dimension reduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Linear-Classifiers-in-Python-0.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Linear Classifiers in Python</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book Community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>